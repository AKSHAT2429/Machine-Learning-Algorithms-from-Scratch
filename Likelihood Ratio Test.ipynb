{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0264_Q8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NOhUmF3SZZ"
      },
      "source": [
        "IMPORTING IMPORTANT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-VsVFqfbGkD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import multi_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFMEdjH23c5P"
      },
      "source": [
        "MOUNTING DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6JGHPgYbTb9",
        "outputId": "9b0ba092-2076-4b71-bc78-60ed8429c827"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvkHQObA3kiF"
      },
      "source": [
        "METRICS FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmp-D-u9siXo"
      },
      "source": [
        "def acc(h, test_output):\n",
        "    TN = 0\n",
        "    TP = 0\n",
        "    FN = 0\n",
        "    FP = 0\n",
        "    for i in range(test_output.shape[0]):\n",
        "        if (h[i] == test_output[i]) & (test_output[i] == 0):\n",
        "            TN += 1\n",
        "        elif (h[i] == test_output[i]) & (test_output[i] == 1):\n",
        "            TP += 1\n",
        "        elif (h[i] == 0) & (test_output[i] == 1):\n",
        "            FN += 1\n",
        "        elif (h[i] == 1) & (test_output[i] == 0):\n",
        "            FP += 1\n",
        "\n",
        "    SE = TP / (TP + FN)\n",
        "    SP = TN / (TN + FP)\n",
        "    Acc = (TP + TN) / (TP + FN + TN + FP)\n",
        "    return SE, SP, Acc*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErTPtQft34cd"
      },
      "source": [
        "LIKELIHOOD RATIO TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMRQfZvbbpWl"
      },
      "source": [
        "def func(train_output,train_features,test_output,test_features):\n",
        "  c0 = 0\n",
        "  c1 = 0\n",
        "  mean0 = 0\n",
        "  mean1 = 0\n",
        "  for i in range(train_output.shape[0]):\n",
        "      if train_output[i] == 0:\n",
        "          c0 += 1\n",
        "          mean0 += train_features[i]\n",
        "\n",
        "      else:\n",
        "          c1 += 1\n",
        "          mean1 += train_features[i]\n",
        "\n",
        "  Py0 = c0 / train_output.shape[0]\n",
        "  Py1 = c1 / train_output.shape[0]\n",
        "  mean0 = mean0 / c0\n",
        "  mean1 = mean1 / c1\n",
        "\n",
        "  cov1 = np.cov((train_features - mean0).T)\n",
        "  cov2 = np.cov((train_features - mean1).T)\n",
        "\n",
        "  y = []\n",
        "  for i in range(test_features.shape[0]):\n",
        "      p1 = np.exp(-0.5 * multi_dot([(test_features[i] - mean0),\n",
        "                                    np.linalg.inv(cov1),\n",
        "                                    (test_features[i] - mean0).T]))\n",
        "      \n",
        "      cond_y1 = p1 / (np.power(2 * np.pi, 2) *\n",
        "                      np.power(np.linalg.det(cov1), 0.5))\n",
        "      \n",
        "      p2 = np.exp(-0.5 * multi_dot([(test_features[i] - mean1),\n",
        "                                    np.linalg.inv(cov2),\n",
        "                                    (test_features[i] - mean1).T]))\n",
        "      \n",
        "      cond_y2 = p2 / (np.power(2 * np.pi, 2) *\n",
        "                      np.power(np.linalg.det(cov2), 0.5))\n",
        "      \n",
        "      P1 = cond_y1 / cond_y2\n",
        "      P2 = Py1 / Py0\n",
        "      if P1 > P2:\n",
        "          y.append(0)\n",
        "      else:\n",
        "          y.append(1)\n",
        "  \n",
        "  return print(\"(SE,SP,Accuracy) =\",acc(y, test_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76kWCPbo37BY"
      },
      "source": [
        "DATA PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzpMC3FHnn_A"
      },
      "source": [
        "from random import Random\n",
        "data = pd.read_excel(\"/content/gdrive/MyDrive/NNFL_ASSIGNMENT_1/data_q4_q5.xlsx\")\n",
        "Random(14).shuffle(data.values)\n",
        "X = data.drop(\"diagnosis\",axis=1)\n",
        "y = data[\"diagnosis\"]\n",
        "y = (y == 'M')\n",
        "\n",
        "def five_fold(X,y):\n",
        "  \n",
        "  m = len(y)\n",
        "  for i in range(5):\n",
        "    X_test = X[int(i*m*0.2):int((i+1)*m*0.2)]\n",
        "    X_train = pd.concat([X, X_test, X_test]).drop_duplicates(keep=False)\n",
        "    y_test = y[int(i*m*0.2):int((i+1)*m*0.2)]\n",
        "    y_train = y.drop(y_test.index)\n",
        "\n",
        "    train_features = np.asarray(X_train)\n",
        "    test_features = np.asarray(X_test)\n",
        "    train_output = np.asarray(y_train)\n",
        "    test_output = np.asarray(y_test)\n",
        "\n",
        "    x = []\n",
        "    mean = []\n",
        "    std = []\n",
        "    for i in range(train_features.shape[1]):\n",
        "        x.append((train_features[:, i] - np.mean(train_features[:, i])) /\n",
        "                np.std(train_features[:, i]))\n",
        "        mean.append(np.mean(train_features[:, i]))\n",
        "        std.append(np.std(train_features[:, i]))\n",
        "\n",
        "    train_features = np.array(x).T\n",
        "\n",
        "    x = []\n",
        "    for i in range(test_features.shape[1]):\n",
        "        x.append((test_features[:, i] - mean[i]) / std[i])\n",
        "\n",
        "    test_features = np.array(x).T\n",
        "\n",
        "    func(train_output,train_features,test_output,test_features)  \n",
        "\n",
        "  return print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDXFsb4b4AwZ"
      },
      "source": [
        "ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP3CMa3lrnL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cb2906-84b4-4c03-8e09-708fdf3ff640"
      },
      "source": [
        "five_fold(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SE,SP,Accuracy = (0.6911764705882353, 0.9777777777777777, 80.53097345132744)\n",
            "SE,SP,Accuracy = (0.7142857142857143, 1.0, 87.71929824561403)\n",
            "SE,SP,Accuracy = (0.85, 1.0, 94.73684210526315)\n",
            "SE,SP,Accuracy = (0.896551724137931, 1.0, 97.36842105263158)\n",
            "SE,SP,Accuracy = (0.8846153846153846, 1.0, 97.36842105263158)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqwC8kgl4M_J"
      },
      "source": [
        "OVERALL ACCURACY : 91.54%"
      ]
    }
  ]
}